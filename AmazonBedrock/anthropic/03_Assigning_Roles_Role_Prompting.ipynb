{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bölüm 3: Rol Atama (Rol Prompt'lama)\n",
    "\n",
    "- [Ders](#lesson)\n",
    "- [Alıştırmalar](#exercises)\n",
    "- [Örnek Oyun Alanı](#example-playground)\n",
    "\n",
    "## Kurulum\n",
    "\n",
    "API anahtarınızı yüklemek ve.*yardımcı fonksiyonunu oluşturmak için aşağıdaki kurulum hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet\n",
    "\n",
    "# Import the hints module from the utils package\n",
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import hints\n",
    "\n",
    "# Python'un yerleşik düzenli ifade kütüphanesini içe aktar\n",
    "import re\n",
    "from anthropic import AnthropicBedrock\n",
    "\n",
    "%store -r MODEL_NAME\n",
    "%store -r AWS_REGION\n",
    "\n",
    "client = AnthropicBedrock(aws_region=AWS_REGION)\n",
    "\n",
    "def get_completion(prompt, system=''):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        system=system\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ders\n",
    "\n",
    "Continuing on the theme of Claude having no context aside from what you say, it's sometimes important to **prompt Claude to inhabit a specific role (including all necessary context)**. This is also known as role prompting. The more detail to the role context, the better.\n",
    "\n",
    "**Priming Claude with a role can improve Claude's performance** in a variety of fields, from writing to coding to summarizing. It's like how humans can sometimes be helped when told to \"think like a ______\". Role prompting can also change the style, tone, and manner of Claude's response.\n",
    "\n",
    "**Note:** Role prompting can happen either in the system prompt or as part of the User message turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Örnekler\n",
    "\n",
    "In the example below, we see that without role prompting, Claude provides a **straightforward and non-stylized answer** when asked to give a single sentence perspective on skateboarding.\n",
    "\n",
    "However, when we prime Claude to inhabit the role of a cat, Claude's perspective changes, and thus **Claude's response tone, style, content adapts to the new role**. \n",
    "\n",
    "**Note:** A bonus technique you can use is to **provide Claude context on its intended audience**. Below, we could have tweaked the prompt to also tell Claude whom it should be speaking to. \"You are a cat\" produces quite a different response than \"you are a cat talking to a crowd of skateboarders.\n",
    "\n",
    "Here is the prompt without role prompting in the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same user question, except with role prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use role prompting as a way to get Claude to emulate certain styles in writing, speak in a certain voice, or guide the complexity of its answers. **Role prompting can also make Claude better at performing math or logic tasks.**\n",
    "\n",
    "For example, in the example below, there is a definitive correct answer, which is yes. However, Claude gets it wrong and thinks it lacks information, which it doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we **prime Claude to act as a logic bot**? How will that change Claude's answer? \n",
    "\n",
    "It turns out that with this new role assignment, Claude gets it right. (Although notably not for all the right reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** What you'll learn throughout this course is that there are **many prompt engineering techniques you can use to derive similar results**. Which techniques you use is up to you and your preference! We encourage you to **experiment to find your own prompt engineering style**.\n",
    "\n",
    "Yukarıdaki içeriği değiştirmeden ders prompt'larıyla deney yapmak istiyorsanız, ders notebook'unun en altına kaydırın ve.*ziyaret edin [**Örnek Oyun Alanı**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Alıştırmalar\n",
    "- [Exercise 3.1 - Math Correction](#exercise-31---math-correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 - Math Correction\n",
    "In some instances, **Claude may struggle with mathematics**, even simple mathematics. Below, Claude incorrectly assesses the math problem as correctly solved, even though there's an obvious arithmetic mistake in the second step. Note that Claude actually catches the mistake when going through step-by-step, but doesn't jump to the conclusion that the overall solution is wrong.\n",
    "\n",
    "Modify the `PROMPT` and / or the `SYSTEM_PROMPT` to make Claude grade the solution as `incorrectly` solved, rather than correctly solved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt - if you don't want to use a system prompt, you can leave this variable set to an empty string\n",
    "SYSTEM_PROMPT = \"\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this equation solved correctly below?\n",
    "\n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"\n",
    "\n",
    "# Claude'un yanıtını al\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Alıştırma doğruluğunu puanlama fonksiyonu\n",
    "def grade_exercise(text):\n",
    "    if \"incorrect\" in text or \"not correct\" in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Claude'un yanıtını yazdır and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- PUANLAMA ---------------------------\")\n",
    "print(\"Bu alıştırma doğru şekilde çözüldü:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Bir ipucu istiyorsanız, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hints.exercise_3_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tebrikler!\n",
    "\n",
    "Bu noktaya kadar tüm alıştırmaları çözdüyseniz, bir sonraki bölüme geçmeye hazırsınız. İyi prompt'lama!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Örnek Oyun Alanı\n",
    "\n",
    "Bu, prompt örnekleriyle özgürce deney yapabileceğiniz bir alan bu derste gösterilen ve Claude'un yanıtlarını nasıl etkileyebileceğini görmek için prompt'ları değiştirin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Claude'un yanıtını yazdır\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
